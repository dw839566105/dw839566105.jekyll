---
layout:     post
title:      Cupy (教程翻译)
subtitle:   
date:       2020-08-04
author:     BY DW
header-img: img/post/post-bg-2.jpg
catalog: true
tags:
    - GPU
---
[参考资料](https://docs.cupy.dev/en/stable/)

## GPU 基础
Host: CPU和内存
Device: GPU和显存
[GPU的优势](https://blog.csdn.net/xingchenhy/article/details/89352268)
GPU英文全称Graphic Processing Unit，中文翻译为“图形处理器”。与CPU不同，GPU是专门为处理图形任务而产生的芯片。从这个任务定位上面来说，不仅仅在计算机的显卡上面，在手机、游戏机等等各种有多媒体处理需求的地方都可以见到GPU的身影。
在GPU出现之前，CPU一直负责着计算机中主要的运算工作，包括多媒体的处理工作。CPU的架构是有利于X86指令集的串行架构，CPU从设计思路上适合尽可能快的完成一个任务。但是如此设计的CPU在多媒体处理中的缺陷也显而易见：多媒体计算通常要求较高的运算密度、多并发线程和频繁地存储器访问，而由于X86平台中CISC（Complex Instruction Set Computer）架构中暂存器数量有限，CPU并不适合处理这种类型的工作。以Intel为代表的厂商曾经做过许多改进的尝试，从1999年开始为X86平台连续推出了多媒体扩展指令集——SSE（Streaming SIMD Extensions）的一代到四代版本，但由于多媒体计算对于浮点运算和并行计算效率的高要求，CPU从硬件本身上就难以满足其巨大的处理需求，仅仅在软件层面的改并不能起到根本效果。

对于GPU来说，它的任务是在屏幕上合成显示数百万个像素的图像——也就是同时拥有几百万个任务需要并行处理，因此GPU被设计成可并行处理很多任务，而不是像CPU那样完成单任务。

CPU和GPU架构差异很大，CPU功能模块很多，能适应复杂运算环境；GPU构成则相对简单，目前流处理器和显存控制器占据了绝大部分晶体管。CPU中大部分晶体管主要用于构建控制电路（比如分支预测等）和Cache，只有少部分的晶体管来完成实际的运算工作。而GPU的控制相对简单，且对Cache的需求小，所以大部分晶体管可以组成各类专用电路、多条流水线，使得GPU的计算速度有了突破性的飞跃，拥有了更强大的处理浮点运算的能力。

CPU结构: 每个core代表核，更大的为存储单元Cache和控制单元Memory Controller。
![CPU结构](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/Chip.png)
GPU结构：更多的面积用于处理任务
![GPU结构](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/GPU_stucture.png)
##### 流多处理器(Stream MultiProcessing, SM)
![SM](https://github.com/dw839566105/dw839566105.github.io/raw/master/img/GPU/SM.png)
一个 GPU 包含多个 Streaming Multiprocessor ，而每个 Streaming Multiprocessor 又包含多个处理不同数据类型的core 。寄存器和存储单元 Streaming Multiprocessors 支持并发执行多达几百的 thread.  
16个core共享一个解码器，32个共享一个上下文，WARP， 共享一个存储单元（较快）。
![1](https://github.com/dw839566105/dw839566105.github.io/raw/master/img/GPU/GPU_stucture1.png)  
一个 thread block 只能调度到一个 Streaming Multiprocessor 上运行，直到 thread block 运行完毕，不能存在于多个SM中。一个 Streaming Multiprocessor 可以同时运行多个thread block。

CUDA中的内存有可读写的全局内存，以及只读的纹理内存(texture memory,更适合于那种需要在图像间插值的应用? )以及常量内存(constant memory,用于保存在Kernel执行期间不会发生变化的数据。NVIDIA硬件提供64KB的Constan Memory。在某些情况，用Constant Memory替换Global Memory能有效的减少内存带宽。)
而shared memory为block私有，local memory为thread私有，读写速度快。
![Memory](https://github.com/dw839566105/dw839566105.github.io/raw/master/img/GPU/Memory.png)

## CUDA 计算
### 关键术语

### 编程
    @cuda.git
    def func(array):
        tx = cuda.blockIdx.x * cuda.blockdim.x + cuda.threadIdx.x
        ty = cuda.blockIdx.y * cuda.blockdim.y + cuda.threadIdx.y
        Then do sth to array[tx, ty]  
其中blockIdx与blockdim以及threadIdx共同确定了线程的ID

![ID1](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/CUDA_thread_index1.png)  
![ID2](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/CUDA_thread_index2.png)  
![ID3](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/CUDA_thread_index3.png)  
![ID4](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/CUDA_thread_index4.png)  
![ID5](https://raw.githubusercontent.com/dw839566105/dw839566105.github.io/master/img/GPU/CUDA_thread_index5.png)  

## CuPy基础
### 概述
Cupy是CUDA对numpy多维数组计算兼容性的提升，由cupy.ndarray组成，核心包括多维数组类和多个函数。支持numpy接口的子集。
以下为支持Numpy接口的子集：
+ Basic indexing (indexing by ints, slices, newaxes, and Ellipsis)
+ Most of Advanced indexing (except for some indexing patterns with boolean masks)
+ Data types (dtypes): bool_, int8, int16, int32, int64, uint8, uint16, uint32, uint64, float16, float32, float64, complex64, complex128
+ Most of the array creation routines (empty, ones_like, diag, etc.)
+ All operators with broadcasting
+ All universal functions for elementwise operations (except those for complex numbers).
+ Linear algebra functions, including product (dot, matmul, etc.) and decomposition (cholesky, svd, etc.), accelerated by cuBLAS.
+ Reduction along axes (sum, max, argmax, etc.)

CuPy还包括以下一些特征：
+ User-defined elementwise CUDA kernels
+ User-defined reduction CUDA kernels
+ Fusing CUDA kernels to optimize user-defined calculation
+ Customizable memory allocator and memory pool
+ cuDNN utilities

CuPy 使用即时的综合体(?)：当需要调用一个核时，会根据数据形状和类型来优化编译代码，并传输给GPU设备在核中执行。编译的代码缓存位于$(HOME)/.cupy/kernel_cache目录，可通过设置环境变量CUPY_CACHE_DIR改变。第一次调用核时可能会比较慢，第二次就会解决。CuPy这个过程中也会将编译代码的缓存输入GPU设备，减少了进一步调用的核转换的时间。

